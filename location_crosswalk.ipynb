{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geocoder\n",
    "import requests\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "import json \n",
    "from sqlalchemy.sql import text\n",
    "import boto3\n",
    "\n",
    "from File_Utilities import FileTools\n",
    "import DB_Utilities\n",
    "DBTools = DB_Utilities.DBTools()  # instantiate the class\n",
    "FileTools.MYDIR = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('location')\n",
    "geolocator = Nominatim(user_agent=\"UVaPatent22Capstone_DataScience\")\n",
    "null_response = {'original_state' : \"\",'original_city' : \"\",'county_GEOID' : \"\",'county_fip' :\"\", 'county_BASENAME' :\"\",'state_fip' :\"\",'state_BASENAME' : \"\",'state_STUSAB' : \"\",'city_BASENAME' : \"\", 'city_NAME' : \"\",  'status' : \"\" }\n",
    "\n",
    "\n",
    "def get_coordinates_aws(city, state):    \n",
    "    # THis costs money...\n",
    "    try:\n",
    "        result = client.search_place_index_for_text(FilterCountries=['USA'], IndexName='City_State_lookup', Text=f'{city}, {state}', MaxResults=3)\n",
    "        # print(f'The type of this variable is : {type(result)}')\n",
    "        lat = result['Results'][0]['Place']['Geometry']['Point'][0]\n",
    "        long = result['Results'][0]['Place']['Geometry']['Point'][1]\n",
    "        return True, str(lat), str(long), result\n",
    "    except:\n",
    "        return False, \"\", \"\", {}\n",
    "\n",
    "\n",
    "def get_coordinates_Nominatim(city, state):    \n",
    "    # Nominatim requests that we only make 1 request per second, otherwise we might get blocked.\n",
    "    try:\n",
    "        # location = geolocator.geocode({'city':city, 'state':state})\n",
    "        location = geolocator.geocode(f'{city} {state}', exactly_one=False, limit=3, addressdetails=True )\n",
    "        # print(location)\n",
    "        time.sleep(1)\n",
    "        # return True, str(location.latitude), str(location.longitude), location      \n",
    "        return True, str(location.longitude), str(location.latitude), location      \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        time.sleep(1)\n",
    "        return False, \"\", \"\", {}\n",
    "\n",
    "def get_county_information_from_census(lat, long, city, state):\n",
    "    # print (f'Lat : {lat }, Long : {long}')\n",
    "    url = f'https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lat}&y={long}&benchmark=4&vintage=4&format=json'\n",
    "    form_url = f'https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lat}&y={long}&benchmark=4&vintage=4'\n",
    "    # print(form_url)\n",
    "\n",
    "# Probably should be its own class at this point.\n",
    "    try:\n",
    "        response = requests.get(url)        \n",
    "        if(response.status_code != 200):\n",
    "            raise        \n",
    "        data = response.json()\n",
    "\n",
    "        county_GEOID = data['result']['geographies']['Counties'][0]['GEOID']    \n",
    "        county_fip = data['result']['geographies']['Counties'][0]['COUNTY']\n",
    "        county_BASENAME = data['result']['geographies']['Counties'][0]['BASENAME']\n",
    "\n",
    "        state_fip = data['result']['geographies']['States'][0]['STATE']\n",
    "        state_BASENAME = data['result']['geographies']['States'][0]['BASENAME']\n",
    "        state_STUSAB = data['result']['geographies']['States'][0]['STUSAB'] \n",
    "\n",
    "        city_BASENAME = data['result']['geographies']['County Subdivisions'][0]['BASENAME'] \n",
    "        city_NAME = data['result']['geographies']['County Subdivisions'][0]['NAME']  \n",
    "\n",
    "\n",
    "    except:\n",
    "        return null_response\n",
    "\n",
    "\n",
    "\n",
    "    print(f'{city_BASENAME} , {state_BASENAME} , {county_BASENAME} , {county_GEOID}')\n",
    "    census_object = {\n",
    "        'original_state' : state,\n",
    "        'original_city' : city,\n",
    "        'county_GEOID' : county_GEOID ,\n",
    "        'county_fip' :county_fip, \n",
    "        'county_BASENAME' :county_BASENAME ,\n",
    "        'state_fip' :state_fip ,\n",
    "        'state_BASENAME' : state_BASENAME ,\n",
    "        'state_STUSAB' : state_STUSAB ,\n",
    "        'city_BASENAME' : city_BASENAME, \n",
    "        'city_NAME' : city_NAME , \n",
    "        'form_url' : form_url,        \n",
    "        'status' : state_STUSAB == state } \n",
    "\n",
    "    return census_object\n",
    "\n",
    "\n",
    "\n",
    "def geocode_lat_long(lat, long, city=\"\", state=\"\"):\n",
    "    # print(\"  \")\n",
    "    # print(f'{city} , {state}')\n",
    "\n",
    "\n",
    "    if DBTools.get_row_count(\"aws_lookup_cache\", f\"city = '{city}' and state = '{state}'\") == 0: \n",
    "        print(f\"Geocoding {Lat}, {long}\")      \n",
    "        census_lookup_result = get_county_information_from_census(lat, long, city, state)\n",
    "        DBTools.insert_location_lookup_cache(city = city\n",
    "                                        , state = state\n",
    "                                        , geocode_response = {}\n",
    "                                        , census_lookup_result = census_lookup_result\n",
    "                                        , lat = lat\n",
    "                                        , long = long\n",
    "                                        )\n",
    "\n",
    "        return census_lookup_result\n",
    "\n",
    "    else:\n",
    "        print(f\"{city}, {state} already exists in the cache\")\n",
    "        return null_response\n",
    "\n",
    "\n",
    "def geocode_city_state(city, state, geocoder_service='aws'):\n",
    "    # print(\"  \")\n",
    "    # print(f'{city} , {state}')\n",
    "\n",
    "\n",
    "    if DBTools.get_row_count(\"aws_lookup_cache\", f\"city = '{city}' and state = '{state}'\") == 0: \n",
    "        print(f\"Geocoding {city}, {state}\")      \n",
    "        if(geocoder_service == 'aws'):\n",
    "            geocode_success, lat, long, geocode_response = get_coordinates_aws(city, state)\n",
    "        else:\n",
    "            geocode_success, lat, long, geocode_response = get_coordinates_Nominatim(city, state)\n",
    "\n",
    "        if (geocode_success == False):\n",
    "            return null_response\n",
    "        else:\n",
    "\n",
    "            census_lookup_result = get_county_information_from_census(lat, long, city, state)\n",
    "            DBTools.insert_location_lookup_cache(city = city\n",
    "                                            , state = state\n",
    "                                            , geocode_response = geocode_response\n",
    "                                            , census_lookup_result = census_lookup_result\n",
    "                                            , lat = lat\n",
    "                                            , long = long\n",
    "                                            )\n",
    "\n",
    "        return census_lookup_result\n",
    "\n",
    "    else:\n",
    "        print(f\"{city}, {state} already exists in the cache\")\n",
    "        return null_response\n",
    "\n",
    "        \n",
    "    # To see the results in an html form.\n",
    "    # https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x=-70.1441014&y=44.671539&benchmark=4&vintage=4\n",
    "    # https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x=-89.7134&y=45.6038&benchmark=4&vintage=4\n",
    "    \t\n",
    "\n",
    "# census_lookup_result = geocode_city_state('Parkridge','NJ', geocoder_service='aws')\n",
    "# using Nominatim geocoder - it doesn't do a good a job of fuzzy matching. There might be a way to get it to match better...but it's also free.\n",
    "# census_lookup_result = geocode_city_state('Parkridge','NJ', geocoder_service='Nominatim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the geocoder, could write this into a unit test.\n",
    "test = False\n",
    "if test:\n",
    "    null_response = {'original_state' : \"\",'original_city' : \"\",'county_GEOID' : \"\",'county_fip' :\"\", 'county_BASENAME' :\"\",'state_fip' :\"\",'state_BASENAME' : \"\",'state_STUSAB' : \"\",'city_BASENAME' : \"\", 'city_NAME' : \"\",  'status' : \"\" }\n",
    "    test_list = [\n",
    "        {'city' : 'city', 'state' : 'state', \"geocode_response\" : {\"something\" : \"something\"} , \"census_lookup_result\" : null_response}, \n",
    "        {'city' : 'city1', 'state' : 'state1', \"geocode_response\" : {\"something\" : \"something\"} , \"census_lookup_result\" : null_response}, \n",
    "        {'city' : 'city2', 'state' : 'state2', \"geocode_response\" : {\"something\" : \"something\"} , \"census_lookup_result\" : null_response}, \n",
    "        {'city' : 'city3', 'state' : 'state3', \"geocode_response\" : {\"something\" : \"something\"} , \"census_lookup_result\" : null_response}]\n",
    "\n",
    "    for i in test_list:\n",
    "        city = i['city']\n",
    "        state = i['state']\n",
    "        geocode_response = i['geocode_response']\n",
    "        census_lookup_result = i['census_lookup_result']\n",
    "        DBTools.insert_location_lookup_cache(city=city, state=state, geocode_response=geocode_response, census_lookup_result=census_lookup_result, lat=\"123.456\", long=\"456.789\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the locations that we need from our data work\n",
    "pregrant_locations_file = r\"./data/pregrant/pregrant_locations.csv\"\n",
    "_pregrant_locations_df = pd.read_csv(pregrant_locations_file)\n",
    "\n",
    "# All the locations\n",
    "location_file = r\"./data/pregrant/location.tsv\"\n",
    "_location_df = pd.read_csv(location_file, sep='\\t')\n",
    "\n",
    "# Seriously, these leading zeros are annoying.\n",
    "_location_df[['state_fips', 'county_fips']] = _location_df[['state_fips','county_fips']].fillna(\"\")\n",
    "_location_df.loc[_location_df.state_fips!=\"\", 'state_fips'] = _location_df.loc[_location_df.state_fips!=\"\", 'state_fips'].astype(str).str.replace(\"\\.0\", \"\").str.zfill(2)\n",
    "_location_df.loc[_location_df.county_fips!=\"\", 'county_fips'] = _location_df.loc[_location_df.county_fips!=\"\", 'county_fips'].astype(str).str.replace(\"\\.0\", \"\").str.zfill(5)\n",
    "DBTools.insert_df(_location_df, \"pregrant_location_unfiltered\")\n",
    "\n",
    "# _location_df.query(\"county_fips != ''\").sort_values(by=['county_fips'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are only interested in the locations that are in the pregrant locations file that have missing data.\n",
    "reduced_location_df = pd.merge(_pregrant_locations_df, _location_df, left_on=['location_id'], right_on=['id'], how='left')\n",
    "print(reduced_location_df.shape)\n",
    "reduced_location_df = reduced_location_df.query(\"country == 'US' & county_fips == '' & city != '' & state != '' \", engine=\"python\")\n",
    "print(reduced_location_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_location_df.query(\"id=='baa6fcdc-cb8e-11eb-9615-121df0c29c1e'\")\n",
    "# _location_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need all the data to join back once we have geocoded the locations.\n",
    "reinsert = False\n",
    "if reinsert:\n",
    "    pregrant_location_all_df = pd.merge(_pregrant_locations_df, _location_df, left_on=['location_id'], right_on=['id'], how='left')\n",
    "    DBTools.insert_df(pregrant_location_all_df, \"pregrant_location_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually run the geocoder and persist the results.\n",
    "# We need to geta dataframe from the database for the final results.\n",
    "rerun = False\n",
    "if rerun:\n",
    "    reduced_location_df.apply(lambda x: geocode_city_state(x.city, x.state), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_crosswalk_df = DBTools.get_df(\"pregrant_location_crosswalk\", \"GEOID != ''\")\n",
    "location_crosswalk_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a file\n",
    "\n",
    "# I'm adding in a dummy row so the GEOIDS are string and not numeric. It won't match on anything else.\n",
    "location_crosswalk_df_dummy = location_crosswalk_df.head(1).copy()\n",
    "location_crosswalk_df_dummy['id'] = \"_\"\n",
    "location_crosswalk_df_dummy['GEOID'] = \"_\"\n",
    "location_crosswalk_df = pd.concat([location_crosswalk_df, location_crosswalk_df_dummy])\n",
    "\n",
    "\n",
    "location_crosswalk_df.to_csv(\"./data/pregrant/location_crosswalk.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a csv into dataframe\n",
    "reload = pd.read_csv(\"./data/pregrant/location_crosswalk.csv\", low_memory=False)\n",
    "reload.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('UVACapstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1320d6b9c24963eeab91ed3c1b469bbfc0dc38b81cdaee0abc39ad090f12f690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
