{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to download data.\n",
    "\n",
    "Useful for recreating data that we used in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests, json\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse, unquote\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "import cgi\n",
    "from requests.exceptions import RequestException\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "MYDIR = (\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data folder already exists.\n"
     ]
    }
   ],
   "source": [
    "def check_directory(directory_name):\n",
    "    '''Check if directory exists, if not, create it'''\n",
    "    # You should change 'test' to your preferred folder.\n",
    "    CHECK_FOLDER = os.path.exists(f'{directory_name}')    \n",
    "    # If folder doesn't exist, then create it.\n",
    "    if not CHECK_FOLDER:\n",
    "        os.makedirs(directory_name)\n",
    "        print(\"created folder : \", directory_name)\n",
    "    else:\n",
    "        print(directory_name, \"folder already exists.\")\n",
    "\n",
    "check_directory(MYDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_file_path(filename):\n",
    "    return os.path.join(MYDIR, filename)\n",
    "\n",
    "def get_file(url, filename=None):\n",
    "\n",
    "    try:\n",
    "        with requests.get(url) as r:\n",
    "            \n",
    "            if filename:\n",
    "                pass\n",
    "            elif \"Content-Disposition\" in r.headers.keys():\n",
    "                value, params = cgi.parse_header(r.headers[\"Content-Disposition\"])\n",
    "                filename = params[\"filename\"]               \n",
    "            else:\n",
    "                filename = unquote(urlparse(url).path.split(\"/\")[-1])\n",
    "                     \n",
    "            full_file_path = get_full_file_path(filename)\n",
    "            open(full_file_path, \"wb\").write(r.content) \n",
    "            print(f'Saved {full_file_path}')\n",
    "    except RequestException as e:\n",
    "        print(e)\n",
    "\n",
    "    return full_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data\\granted_patent_data.html\n",
      "Saved data\\pregrant_patent_data.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data\\\\pregrant_patent_data.html'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "granted_patent_data_file = 'granted_patent_data.html'\n",
    "granted_patent_data_url = 'https://patentsview.org/download/data-download-tables'\n",
    "get_file(granted_patent_data_url, granted_patent_data_file)\n",
    "\n",
    "pregrant_patent_data_file = 'pregrant_patent_data.html'\n",
    "pregrant_patent_data_url = 'https://patentsview.org/download/pg-download-tables'\n",
    "get_file(pregrant_patent_data_url, pregrant_patent_data_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(get_full_file_path(granted_patent_data_file)) as fp:\n",
    "    soup = BeautifulSoup(fp, 'html.parser')    \n",
    "    granted_patent_data_links = soup.find_all(href=re.compile(\"s3\"))\n",
    "granted_patent_data_links = [link.get('href') for link in granted_patent_data_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/application.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/assignee.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/botanic.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/cpc_current.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/cpc_group.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/cpc_subgroup.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/cpc_subsection.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/figures.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/foreigncitation.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/foreign_priority.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/government_interest.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/government_organization.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/inventor.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/ipcr.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/lawyer.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/location.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/mainclass.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/mainclass_current.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/nber.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/nber_category.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/nber_subcategory.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/non_inventor_applicant.tsv.zip\n",
      "File gotten\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/otherreference.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\otherreference.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/patent.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\patent.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/patent_assignee.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\patent_assignee.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/patent_contractawardnumber.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\patent_contractawardnumber.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/patent_govintorg.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\patent_govintorg.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/patent_inventor.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\patent_inventor.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/patent_lawyer.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\patent_lawyer.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/pct_data.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\pct_data.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/persistent_assignee_disambig.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\persistent_assignee_disambig.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/persistent_inventor_disambig.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\persistent_inventor_disambig.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/rawassignee.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\rawassignee.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/rawexaminer.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\rawexaminer.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/rawinventor.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\rawinventor.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/rawlawyer.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\rawlawyer.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/rawlocation.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\rawlocation.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/rel_app_text.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\rel_app_text.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/subclass.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\subclass.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/subclass_current.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\subclass_current.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/usapplicationcitation.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\usapplicationcitation.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/uspatentcitation.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\uspatentcitation.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/uspc.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\uspc.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/uspc_current.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\uspc_current.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/usreldoc.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\usreldoc.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/us_term_of_grant.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\us_term_of_grant.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/wipo.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\wipo.tsv.zip\n",
      "Getting https://s3.amazonaws.com/data.patentsview.org/download/wipo_field.tsv.zip\n",
      "File Not Gotten\n",
      "Saved data\\wipo_field.tsv.zip\n"
     ]
    }
   ],
   "source": [
    "onlyfiles = [f for f in listdir(MYDIR) if isfile(join(MYDIR, f))]\n",
    "for url in granted_patent_data_links:\n",
    "    print(f'Getting {url}')\n",
    "    filename = unquote(urlparse(url).path.split(\"/\")[-1])\n",
    "    if(filename in onlyfiles):\n",
    "        print(\"File gotten\")\n",
    "    else:\n",
    "        print(\"File Not Gotten\")\n",
    "        filename = get_file(url)\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table schemas from the data dictionary\n",
    "\n",
    "Gives us proper data types and protects us from importing bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My first thought was to generate this straight from the html data dictionary page, but it's a mess\n",
    "# I've left this in here in case anyone wants to give it a shot.\n",
    "file = 'data-download-dictionary.html'\n",
    "url = 'https://patentsview.org/download/data-download-dictionary'\n",
    "get_file(url, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I created patent_datadictionary.csv by hand because the html was just not easy to parse...\n",
    "# Could go back and get this from the above cell but I'm not sure it is worth doing it.\n",
    "df = pd.read_csv(get_full_file_path('patent_datadictionary.csv'), header=None)\n",
    "df.columns = ['field', 'type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Database table schemas from patent_datadictionary.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each table name is indicated by having a null type\n",
    "table_names = df[df['type'].isnull()]\n",
    "# just the actual table names and their place in the df\n",
    "table_names_index = table_names.index.to_list()\n",
    "\n",
    "# Iterating over the list of table names, finding what fields belong to them and then building the CREATE TABLE syntax.\n",
    "# In an ideal work you build your tables in here as well but I just printed them out and ran them in my SQL IDE.\n",
    "# I'll go back in and add the table creation here soon. This solution is real clunky.\n",
    "for index, value in enumerate(table_names_index):    \n",
    "    \n",
    "    try:\n",
    "        _df = df.iloc[table_names_index[index]:table_names_index[index+1], :]\n",
    "    except:        \n",
    "        _df = df.iloc[table_names_index[index]:len(df.index), :]\n",
    "\n",
    "    _df = _df.reset_index()  # make sure indexes pair with number of rows\n",
    "\n",
    "    for index, row in _df.iterrows():\n",
    "        if(index == 0):\n",
    "            create_table_string = f'CREATE TABLE {row[\"field\"]} (\\n'\n",
    "        elif(index > 1):\n",
    "            create_table_string += f'     {row[\"field\"]} {row[\"type\"]},\\n'\n",
    "        \n",
    "    create_table_string = create_table_string[:-2] + '\\n);'        \n",
    "    print(create_table_string)\n",
    "    print('-- '*50)   \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data into MYSQL\n",
    "\n",
    "I used MYSQL Workbench to load the data, it's pretty big so I wanted to minimize any middlemen (like dataframes). There probably is a cleaner way to load it all from this notebook...\n",
    "\n",
    "You can either download all the data with this notebook or just go to the UVA Box with all the files and download them from there.\n",
    "\n",
    "Here is the SQL to load it from Workbench\n",
    "\n",
    "<code>\n",
    "SET GLOBAL local_infile = true;\n",
    "\n",
    "\n",
    "truncate table patent; \n",
    "\n",
    "\n",
    "LOAD DATA \n",
    "\tLOCAL INFILE 'path/to/file/patent.tsv' \n",
    "INTO TABLE patent \n",
    "COLUMNS \n",
    "\tTERMINATED BY '\\t'\n",
    "\tENCLOSED BY '\"'\n",
    "    IGNORE 1 LINES;\n",
    "\n",
    "</code>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('UVACapstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1320d6b9c24963eeab91ed3c1b469bbfc0dc38b81cdaee0abc39ad090f12f690"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
